
import json
import re
import asyncio

# --- OpenAI (modern client) ---
try:
    from openai import OpenAI
    _USING_RESPONSES_API = True
except Exception:
    # Fallback to legacy interface if needed
    import openai  # type: ignore
    _USING_RESPONSES_API = False

from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes

import tokens  # expects: tokens.API_gpt_token, tokens.telegram_bot_token


# =====================
# Config
# =====================
MODEL = "gpt-4o-mini"  # fast + inexpensive; upgrade as you wish

# JSON Schema for Structured Outputs
BRACHABOT_SCHEMA = {
    "type": "object",
    "properties": {
        "is_food": {"type": "boolean"},
        "category": {
            "type": "string",
            "enum": ["×œ×—×", "××–×•× ×•×ª", "×¤×¨×™_×¢×¥", "×¤×¨×™_××“××”", "×™×™×Ÿ", "×©×”×›×œ", "×œ×_×××›×œ", "×œ×_×™×“×•×¢"],
        },
        "bracha": {
            "type": "string",
            "description": "×”×‘×¨×›×” ×”×¨××©×•× ×” ×”××ª××™××” ××• 'â€”' ×× ×œ× ×××›×œ/×œ× ×™×“×•×¢",
        },
        "explanation": {"type": "string"},
        "notes": {"type": "string"},
    },
    "required": ["is_food", "category", "bracha", "explanation"],
    "additionalProperties": False,
}

# Deterministic mapping (server-side safety)
CATEGORY_TO_BRACHA = {
    "×œ×—×": "×”××•×¦×™× ×œ×—× ××Ÿ ×”××¨×¥",
    "××–×•× ×•×ª": "×‘×•×¨× ××™× ×™ ××–×•× ×•×ª",
    "×¤×¨×™_×¢×¥": "×‘×•×¨× ×¤×¨×™ ×”×¢×¥",
    "×¤×¨×™_××“××”": "×‘×•×¨× ×¤×¨×™ ×”××“××”",
    "×™×™×Ÿ": "×‘×•×¨× ×¤×¨×™ ×”×’×¤×Ÿ",
    "×©×”×›×œ": "×©×”×›×œ × ×”×™×” ×‘×“×‘×¨×•",
}


SYSTEM_PROMPT = """
××ª×” ××•××—×” ×‘×”×œ×›×” ×™×”×•×“×™×ª ×‘×¢× ×™×™× ×™ ×‘×¨×›×•×ª. ××˜×¨×ª×š: ×œ×§×‘×•×¢ ×‘×¨×›×” ×¨××©×•× ×” ××“×•×™×§×ª ×œ×¤×™ ×›×œ×œ×™× ×”×œ×›×ª×™×™× × ×¤×•×¦×™×.
×× ×”×§×œ×˜ ××™× ×• ×××›×œ â€“ ×¢×œ×™×š ×œ×¦×™×™×Ÿ ×–××ª ×‘××¤×•×¨×©. ×”×—×–×¨ JSON ×ª×§×™×Ÿ ×‘×œ×‘×“ ×œ×¤×™ ×”×¡×›×™××” ×©×¡×•×¤×§×”.

×›×œ×œ×™× ×ª××¦×™×ª×™×™×:
- ×œ×—× ×•×“×•××™×• (×¤×ª): "×”××•×¦×™×".
- ×“×’× ×™× ×©××™× × ×œ×—× (×¤×ª ×”×‘××” ×‘×›×¡× ×™×Ÿ, ×¢×•×’×•×ª/×¢×•×’×™×•×ª/×‘×•×¨×§×¡, ×“×™×™×¡×•×ª, ×§×•×¡×§×•×¡/×¤×¡×˜×”/××™×˜×¨×™×•×ª/×‘×•×¨×’×•×œ/××•×¨×– ××‘×•×©×œ×™×): "××–×•× ×•×ª".
- ×¤×¨×™ ×¢×¥ ×××™×ª×™: "×‘×•×¨× ×¤×¨×™ ×”×¢×¥".
- ×’×™×“×•×œ×™ ×§×¨×§×¢ ×©××™× × ×¢×¥ (×œ×¨×‘×•×ª ×‘× × ×”): "×‘×•×¨× ×¤×¨×™ ×”××“××”".
- ×™×™×Ÿ (×™×™×Ÿ ××“×•×, ×™×™×Ÿ ×œ×‘×Ÿ, ×™×™×Ÿ ××ª×•×§, ××™×¥ ×¢× ×‘×™× ×œ×§×™×“×•×©): "×™×™×Ÿ".
- ×‘×©×¨/×“×’×™×/×‘×™×¦×™×/×’×‘×™× ×•×ª/××©×§××•×ª/×××ª×§×™×/×××›×œ×™× ××¢×•×‘×“×™×/×ª×¢×¨×•×‘×•×ª ×œ×œ× ×¨×›×™×‘ ×“×’×Ÿ ×¢×™×§×¨×™: "×©×”×›×œ".
- ×× ×” ××•×¨×›×‘×ª: ×”××¨×›×™×‘ ×”×¢×™×§×¨×™ ×§×•×‘×¢.
- ×× ×–×” ×œ× ×××›×œ: is_food=false, category="×œ×_×××›×œ", bracha="â€”".
- ×× ×—×¡×¨ ××™×“×¢ ××• ×§×™×™××ª ××—×œ×•×§×ª ××©××¢×•×ª×™×ª: category="×œ×_×™×“×•×¢" ×¢× ×”×¡×‘×¨ ×§×¦×¨.

×“×•×’×××•×ª ×§×¦×¨×•×ª (×œ× ×ª×™××•×¨ ××œ×):
- "×ª×¤×•×—" â†’ ×¤×¨×™_×¢×¥/×‘×•×¨× ×¤×¨×™ ×”×¢×¥.
- "×‘× × ×”" â†’ ×¤×¨×™_××“××”/×‘×•×¨× ×¤×¨×™ ×”××“××”.
- "×§×¨×•××¡×•×Ÿ" (×¨×’×™×œ, ×œ× ×§×‘×™×¢×ª ×¡×¢×•×“×”) â†’ ××–×•× ×•×ª/×‘×•×¨× ××™× ×™ ××–×•× ×•×ª.
- "×©× ×™×¦×œ" â†’ ×©×”×›×œ/×©×”×›×œ × ×”×™×” ×‘×“×‘×¨×•.

×”×—×–×¨ ××š ×•×¨×§ JSON â€” ×œ×œ× ×˜×§×¡×˜ × ×•×¡×£.
""".strip()


# =====================
# OpenAI helpers
# =====================
def _coerce_bracha(category: str, bracha_from_model: str) -> str:
    """Prefer deterministic mapping; return 'â€”' for non-food/unknown."""
    category = (category or "").strip()
    bracha_from_model = (bracha_from_model or "").strip()
    if category in ("×œ×_×××›×œ", "×œ×_×™×“×•×¢"):
        return "â€”"
    mapped = CATEGORY_TO_BRACHA.get(category)
    if mapped:
        return mapped
    # Last resort: model's suggestion or default
    return bracha_from_model or "×©×”×›×œ × ×”×™×” ×‘×“×‘×¨×•"


def _legacy_chat_completion(food_name: str, details: str = "") -> dict:
    """Legacy fallback using ChatCompletion with JSON instruction."""
    import openai  # legacy
    openai.api_key = tokens.API_gpt_token
    user_prompt = f'×©× ×”×××›×œ: "{food_name}"\\n×ª×™××•×¨ (××•×¤×¦×™×•× ×œ×™): {details or "â€”"}'
    json_only = (
        "×”×—×–×¨ JSON ×ª×§×™×Ÿ ×‘×œ×‘×“ ×œ×¤×™ ×”×¡×›×™××”: "
        + json.dumps(BRACHABOT_SCHEMA, ensure_ascii=False)
    )

    resp = openai.ChatCompletion.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT + "\\n\\n" + json_only},
            {"role": "user", "content": user_prompt},
        ],
        temperature=0,
    )
    text = resp["choices"][0]["message"]["content"]
    return json.loads(text)


def ask_openai(food_name: str, details: str = "") -> dict:
    """
    Calls OpenAI with Structured Outputs if available; else uses legacy fallback.
    Returns a dict that matches BRACHABOT_SCHEMA.
    """
    if not _USING_RESPONSES_API:
        return _legacy_chat_completion(food_name, details)

    client = OpenAI(api_key=tokens.API_gpt_token)
    user_prompt = f'×©× ×”×××›×œ: "{food_name}"\\n×ª×™××•×¨ (××•×¤×¦×™×•× ×œ×™): {details or "â€”"}'

    resp = client.responses.create(
        model=MODEL,
        input=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": user_prompt},
        ],
        temperature=0,
        response_format={
            "type": "json_schema",
            "json_schema": {"name": "brachabot", "schema": BRACHABOT_SCHEMA},
        },
    )
    # Try to extract the JSON payload robustly
    try:
        text = resp.output[0].content[0].text  # standard path
    except Exception:
        # Fallback: some SDKs expose .output_text or similar
        text = getattr(resp, "output_text", None) or getattr(resp, "content", None)
        if text is None:
            # Last resort: convert to str and try to find JSON in it
            raw = str(resp)
            m = re.search(r"\\{.*\\}", raw, flags=re.S)
            text = m.group(0) if m else "{}"

    return json.loads(text)


# =====================
# Telegram Handlers
# =====================
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "×©×œ×•×! ×©×œ×—/×™ ×©× ×©×œ ×××›×œ ××• ×× ×” (×’× ××•×¨×›×‘×ª) ×•××—×–×™×¨ ××ª ×”×‘×¨×›×” ×”××ª××™××”.\n"
        "×“×•×’××”: '×¡×œ×˜ ×§×™× ×•××” ×¢× ×—×–×” ×¢×•×£', '×ª×¤×•×—', '×§×¨×•××¡×•×Ÿ'."
    )


async def get_bracha(update: Update, context: ContextTypes.DEFAULT_TYPE):
    food_name = (update.message.text or "").strip()
    if not food_name:
        await update.message.reply_text("×©×œ×—/×™ ×©× ×××›×œ ××—×“ ğŸ˜„")
        return

    try:
        data = ask_openai(food_name)
        is_food = bool(data.get("is_food"))
        category = str(data.get("category", "×œ×_×™×“×•×¢"))
        bracha_model = str(data.get("bracha", ""))
        final_bracha = _coerce_bracha(category, bracha_model)

        if not is_food or category == "×œ×_×××›×œ" or final_bracha == "â€”":
            await update.message.reply_text(f"{food_name} ×–×” ×œ× ×××›×œ")
            return

        # Send ONLY the blessing text (as you requested)
        await update.message.reply_text(final_bracha)

    except Exception as e:
        # Fallback if something goes wrong
        await update.message.reply_text("×©×”×›×œ × ×”×™×” ×‘×“×‘×¨×•")


def main():
    app = ApplicationBuilder().token(tokens.telegram_bot_token).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, get_bracha))
    app.run_polling()


if __name__ == "__main__":
    main()
